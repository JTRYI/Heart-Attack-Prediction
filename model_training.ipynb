{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43f958c9-e5db-4c62-940a-868da308cd94",
   "metadata": {},
   "source": [
    "## Model Building and Evaluation of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "687a7db2-e8d6-488d-aa8d-3c5a4922ee69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from scipy.stats import randint\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e8e26c1-fc7b-4977-a2fb-67b7d2747ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting data from the cleaned dataset\n",
    "df = pd.read_csv('data/heart_attack_prediction_cleaned_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fb75648-2b63-4f56-8988-8c2e411af64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Age  Sex  Cholesterol  Heart Rate  Diabetes  Family History  Smoking  \\\n",
      "0    67    1          208          72         0               0        1   \n",
      "1    21    1          389          98         1               1        1   \n",
      "2    21    0          324          72         1               0        0   \n",
      "3    84    1          383          73         1               1        1   \n",
      "4    66    1          318          93         1               1        1   \n",
      "5    54    0          297          48         1               1        1   \n",
      "6    90    1          358          84         0               0        1   \n",
      "7    84    1          220         107         0               0        1   \n",
      "8    20    1          145          68         1               0        1   \n",
      "9    43    0          248          55         0               1        1   \n",
      "10   73    0          373          97         1               1        1   \n",
      "11   71    1          374          70         1               1        1   \n",
      "12   77    1          228          68         1               1        1   \n",
      "13   60    1          259          85         1               1        1   \n",
      "14   88    1          297         102         1               1        1   \n",
      "15   73    1          122          97         1               1        1   \n",
      "16   69    1          379          40         1               1        1   \n",
      "17   38    1          166          56         1               0        1   \n",
      "18   50    0          303         104         1               0        1   \n",
      "19   60    1          145          71         1               0        1   \n",
      "\n",
      "    Obesity  Alcohol Consumption  Exercise Hours Per Week  ...  Income  \\\n",
      "0         0                    0                 4.168189  ...  261404   \n",
      "1         1                    1                 1.813242  ...  285768   \n",
      "2         0                    0                 2.078353  ...  235282   \n",
      "3         0                    1                 9.828130  ...  125640   \n",
      "4         1                    0                 5.804299  ...  160555   \n",
      "5         0                    1                 0.625008  ...  241339   \n",
      "6         0                    1                 4.098177  ...  190450   \n",
      "7         1                    1                 3.427929  ...  122093   \n",
      "8         1                    0                16.868302  ...   25086   \n",
      "9         1                    1                 0.194515  ...  209703   \n",
      "10        0                    1                16.841988  ...   50030   \n",
      "11        1                    1                 8.251995  ...  163066   \n",
      "12        1                    1                19.633268  ...   29886   \n",
      "13        0                    1                17.037374  ...  292173   \n",
      "14        0                    1                15.387605  ...  165300   \n",
      "15        0                    1                14.559664  ...  265839   \n",
      "16        1                    1                 4.184648  ...  267997   \n",
      "17        1                    0                 8.917907  ...   48376   \n",
      "18        0                    1                 4.943580  ...   21501   \n",
      "19        0                    1                 1.892559  ...  234966   \n",
      "\n",
      "          BMI  Triglycerides  Sleep Hours Per Day  Heart Attack Risk  \\\n",
      "0   31.251233            286                    6                  0   \n",
      "1   27.194973            235                    7                  0   \n",
      "2   28.176571            587                    4                  0   \n",
      "3   36.464704            378                    4                  0   \n",
      "4   21.809144            231                    5                  0   \n",
      "5   20.146840            795                   10                  1   \n",
      "6   28.885811            284                   10                  1   \n",
      "7   22.221862            370                    7                  1   \n",
      "8   35.809901            790                    4                  0   \n",
      "9   22.558917            232                    7                  0   \n",
      "10  22.867911            469                    4                  0   \n",
      "11  32.485345            523                    8                  0   \n",
      "12  35.102236            590                    6                  1   \n",
      "13  25.564897            506                    4                  1   \n",
      "14  25.491741            635                    6                  0   \n",
      "15  36.524395            773                    8                  1   \n",
      "16  28.332747             68                    6                  0   \n",
      "17  29.517388            402                    6                  0   \n",
      "18  25.964351            517                    5                  1   \n",
      "19  29.162319            247                    7                  0   \n",
      "\n",
      "    Systolic  Diastolic  Diet_Average  Diet_Healthy  Diet_Unhealthy  \n",
      "0        158         88             1             0               0  \n",
      "1        165         93             0             0               1  \n",
      "2        174         99             0             1               0  \n",
      "3        163        100             1             0               0  \n",
      "4         91         88             0             0               1  \n",
      "5        172         86             0             0               1  \n",
      "6        102         73             0             1               0  \n",
      "7        131         68             1             0               0  \n",
      "8        144        105             1             0               0  \n",
      "9        160         70             0             0               1  \n",
      "10       107         69             1             0               0  \n",
      "11       158         71             1             0               0  \n",
      "12       101         72             0             0               1  \n",
      "13       169         72             0             1               0  \n",
      "14       112         81             0             0               1  \n",
      "15       114         88             1             0               0  \n",
      "16       173         75             1             0               0  \n",
      "17       120         74             0             1               0  \n",
      "18       120        100             1             0               0  \n",
      "19       160         98             0             1               0  \n",
      "\n",
      "[20 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "#Making a copy of the dataframe\n",
    "df_copy = df.copy()\n",
    "\n",
    "#Displaying first 20 rows of data to check if it is the cleaned dataset\n",
    "print(df_copy.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "575aaf0e-3bc7-4fe8-86c7-3b0ba015ee5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_copy['Heart Attack Risk'].to_numpy()\n",
    "\n",
    "del df_copy['Heart Attack Risk']\n",
    "\n",
    "x = df_copy.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25fef888-e1a8-448a-994e-a798deb5d18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffle and split dataset into 0.7 Train Size and 0.3 test size\n",
    "size = 0.30\n",
    "seed = 7\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(x, y, test_size=size,random_state = seed)\n",
    "                                                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5a8a5a-73b8-49ba-b906-ed07f3a47527",
   "metadata": {},
   "source": [
    "### Declaring Models to be Trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f09247bf-73d7-4a8b-9c60-8602086a63b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Models to be trained\n",
    "LR = LogisticRegression(solver='lbfgs', multi_class='auto',max_iter=1000)\n",
    "LDA = LinearDiscriminantAnalysis()\n",
    "KNN = KNeighborsClassifier()\n",
    "DTC = DecisionTreeClassifier()\n",
    "RF = RandomForestClassifier()\n",
    "ADA = AdaBoostClassifier()\n",
    "GB = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bf8ce7-53d5-4599-b36b-2276fc35f32e",
   "metadata": {},
   "source": [
    "### Training the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c34dae57-67e9-4556-8766-f484b4588984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the models\n",
    "LR.fit(X_train,y_train)\n",
    "LDA.fit(X_train,y_train)\n",
    "KNN.fit(X_train,y_train)\n",
    "DTC.fit(X_train,y_train)\n",
    "RF.fit(X_train,y_train)\n",
    "ADA.fit(X_train,y_train)\n",
    "GB.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb2c35e-7e0a-4672-86cc-1f37867c59d5",
   "metadata": {},
   "source": [
    "### Evaluating Model with Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a86e269-6fcb-4d6e-8eda-d314193a1e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.6317991631799164\n",
      "LDA: 0.6317991631799164\n",
      "KNN: 0.5621909471281856\n",
      "DTC: 0.5450741726892354\n",
      "RF: 0.6249524534043363\n",
      "ADA: 0.6276150627615062\n",
      "GB: 0.6298972993533662\n",
      "The best model for test data is LR with an accuracy of 0.6317991631799164\n"
     ]
    }
   ],
   "source": [
    "#Evaluating model with test data\n",
    "\n",
    "# Models to be trained\n",
    "models = [LR, LDA, KNN, DTC, RF, ADA, GB]\n",
    "model_names = ['LR', 'LDA', 'KNN', 'DTC', 'RF', 'ADA', 'GB']\n",
    "\n",
    "# Dictionary to store accuracy scores\n",
    "accuracy_scores = {}\n",
    "\n",
    "# Loop over models\n",
    "for model, name in zip(models, model_names):\n",
    "    # Evaluate the model on test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Print the accuracy for each model\n",
    "    print(f'{name}: {accuracy}')\n",
    "\n",
    "    # Store accuracy score in the dictionary\n",
    "    accuracy_scores[name] = accuracy\n",
    "\n",
    "# Find the best model\n",
    "best_model = max(accuracy_scores, key=accuracy_scores.get)\n",
    "best_accuracy = accuracy_scores[best_model]\n",
    "\n",
    "print(f'The best model for test data is {best_model} with an accuracy of {best_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89c0530-94d4-4d8a-9cac-8c21b9ee0a6e",
   "metadata": {},
   "source": [
    "### Evaluating Model with Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ee61f83-538a-4673-b08e-1b1cf0c02824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.6460710792305184\n",
      "LDA: 0.6460710792305184\n",
      "KNN: 0.7243234431040104\n",
      "DTC: 1.0\n",
      "RF: 1.0\n",
      "ADA: 0.649983697424193\n",
      "GB: 0.6713400717313336\n",
      "The best model for training data is DTC with an accuracy of 1.0\n"
     ]
    }
   ],
   "source": [
    "#Evaluating model with train data\n",
    "\n",
    "# Models to be trained\n",
    "models = [LR, LDA, KNN, DTC, RF, ADA, GB]\n",
    "model_names = ['LR', 'LDA', 'KNN', 'DTC', 'RF', 'ADA', 'GB']\n",
    "\n",
    "# Dictionary to store accuracy scores\n",
    "accuracy_scores_train = {}\n",
    "\n",
    "# Loop over models\n",
    "for model, name in zip(models, model_names):\n",
    "    # Evaluate the model on training data\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "    \n",
    "    # Print the accuracy for each model on training data\n",
    "    print(f'{name}: {accuracy_train}')\n",
    "\n",
    "    # Store accuracy score in the dictionary\n",
    "    accuracy_scores_train[name] = accuracy_train\n",
    "\n",
    "# Find the best model for training data\n",
    "best_model_train = max(accuracy_scores_train, key=accuracy_scores_train.get)\n",
    "best_accuracy_train = accuracy_scores_train[best_model_train]\n",
    "\n",
    "print(f'The best model for training data is {best_model_train} with an accuracy of {best_accuracy_train}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06d19f3-212e-4c23-b575-69c99dc7a128",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### In the evaluation of various classification models, it is evident that the performance, as measured by accuracy, is consistently higher on the training data compared to the test data. This discrepancy suggests a potential issue of overfitting, where models excel in learning the training data but struggle to generalize effectively to new, unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3acd67-812a-4d11-a161-d7d61d7c58c3",
   "metadata": {},
   "source": [
    "### Viewing Feature Importance on RandomForestClassifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "394bd9d2-ee8a-4daf-bc0b-d680745f184c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoking - 0.59%\n",
      "Diet_Unhealthy - 1.04%\n",
      "Diet_Healthy - 1.05%\n",
      "Diet_Average - 1.08%\n",
      "Sex - 1.10%\n",
      "Diabetes - 1.16%\n",
      "Obesity - 1.27%\n",
      "Alcohol Consumption - 1.28%\n",
      "Previous Heart Problems - 1.28%\n",
      "Family History - 1.29%\n",
      "Medication Use - 1.31%\n",
      "Sleep Hours Per Day - 4.07%\n",
      "Stress Level - 4.58%\n",
      "Diastolic - 6.94%\n",
      "Age - 7.36%\n",
      "Heart Rate - 7.52%\n",
      "Systolic - 7.55%\n",
      "Cholesterol - 7.95%\n",
      "Triglycerides - 8.13%\n",
      "Exercise Hours Per Week - 8.20%\n",
      "BMI - 8.35%\n",
      "Income - 8.43%\n",
      "Sedentary Hours Per Day - 8.47%\n"
     ]
    }
   ],
   "source": [
    "# These are the feature labels from our data set\n",
    "feature_labels = np.array(['Age', 'Sex', 'Cholesterol', 'Heart Rate', 'Diabetes', 'Family History', 'Smoking', 'Obesity', 'Alcohol Consumption', 'Exercise Hours Per Week', 'Previous Heart Problems', 'Medication Use', 'Stress Level', 'Sedentary Hours Per Day', 'Income', 'BMI', 'Triglycerides', 'Sleep Hours Per Day', 'Systolic', 'Diastolic', 'Diet_Average', 'Diet_Healthy', 'Diet_Unhealthy'])\n",
    "\n",
    "# Create a numpy array based on the model's feature importances\n",
    "importance = RF.feature_importances_\n",
    "\n",
    "# Sort the feature labels based on the feature importance rankings from the model\n",
    "feature_indexes_by_importance = importance.argsort()\n",
    "\n",
    "# Print each feature label, from most important to least important (reverse order)\n",
    "for index in feature_indexes_by_importance:\n",
    "    print(\"{} - {:.2f}%\".format(feature_labels[index], (importance[index] * 100.0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280eb4e8-1fed-4d0a-ac2a-c053a5cef0cc",
   "metadata": {},
   "source": [
    "#### From the Percentages, We can see that Smoking, Diet_Unhealthy, Diet_Average, Diet_Healthy, Sex, Obesity, Diabetes, Medication Use, Alcohol Consumption, Family History and Previous Heart Problems are Features that are less important when finding out a person's Heart Attack Risk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1443ee-222a-42c4-9bc7-6276b4e85ce9",
   "metadata": {},
   "source": [
    "<!-- ### Performing GridSearch on Logistic Regression based on its performance in terms of accuracy on both the training and test datasets. LR demonstrates a balanced accuracy score, making it a suitable candidate for optimization -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03307ff7-6da2-497b-9f12-ff156dfe7e66",
   "metadata": {},
   "source": [
    "### Doing GridSearch on DecisionTreeClassifier, the worst Model with Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a25f73d-38ef-4c8c-aca2-6a684c5a9875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 128 candidates, totalling 640 fits\n",
      "Best Parameters for Decision Tree Classifier: {'criterion': 'gini', 'max_depth': 3, 'min_samples_leaf': 8, 'min_samples_split': 4, 'splitter': 'random'}\n",
      "Best Accuracy Score for Decision Tree Classifier: 0.6463973324505319\n",
      "GridSearch Decision Tree Classifier with Test Data 0.6317991631799164\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for DecisionTreeClassifier\n",
    "param_grid_dt = {\n",
    "    'criterion': ['entropy', 'gini'],\n",
    "    'splitter': ['random'],\n",
    "    'max_depth': [3, 2, 1, 10],\n",
    "    'min_samples_split': [2, 3, 4, 6],\n",
    "    'min_samples_leaf': [1, 3, 5, 8]\n",
    "}\n",
    "\n",
    "# Create the DecisionTreeClassifier model\n",
    "dt_model = DecisionTreeClassifier()\n",
    "\n",
    "# Create GridSearchCV object for DecisionTreeClassifier\n",
    "grid_search_dt = GridSearchCV(estimator=dt_model, param_grid=param_grid_dt, scoring='accuracy', cv=5, n_jobs=-1, verbose=100)\n",
    "\n",
    "# Fit the DecisionTreeClassifier model to the data\n",
    "grid_search_dt.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and the corresponding accuracy score\n",
    "best_params_dt = grid_search_dt.best_params_\n",
    "best_score_dt = grid_search_dt.best_score_\n",
    "\n",
    "# Testing GridSearch Model with Test Data\n",
    "accuracy_score_grid_search_dt = accuracy_score(y_test, grid_search_dt.predict(X_test))\n",
    "\n",
    "print('Best Parameters for Decision Tree Classifier:', best_params_dt)\n",
    "print('Best Accuracy Score for Decision Tree Classifier:', best_score_dt)\n",
    "\n",
    "print('GridSearch Decision Tree Classifier with Test Data', accuracy_score_grid_search_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1f95c1-73f8-447c-b7b4-0a32991ef61b",
   "metadata": {},
   "source": [
    "### Doing GridSearch on LogisticRegression, the best Model with Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44365dac-2279-4116-baec-fdd7942f47ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n",
      "Best Parameters for Logistic Regression: {'C': 0.01, 'class_weight': None, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'random_state': None, 'solver': 'lbfgs', 'tol': 0.001}\n",
      "Best Accuracy Score for Logistic Regression: 0.64607106817647\n",
      "GridSearch Logistic Regression with Test Data 0.6317991631799164\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for Logistic Regression\n",
    "param_grid_lr = {\n",
    "     'penalty': ['l2'],  # 'l1' is removed since lbfgs does not support it\n",
    "    'tol': [1e-3, 1e-4],\n",
    "    'C': [0.01, 0.1, 1],\n",
    "    'fit_intercept': [True, False],\n",
    "    'class_weight': [None, 'balanced'],\n",
    "    'solver': ['lbfgs', 'liblinear'],\n",
    "    'max_iter': [100, 200, 300],\n",
    "    'random_state': [None, 42]\n",
    "}\n",
    "\n",
    "# Create the Logistic Regression model\n",
    "lr_model = LogisticRegression()\n",
    "\n",
    "# Create GridSearchCV object for Logistic Regression\n",
    "grid_search_lr = GridSearchCV(estimator=lr_model, param_grid=param_grid_lr, scoring='accuracy', cv=5, n_jobs=-1, verbose=100)\n",
    "\n",
    "# Fit the Logistic Regression model to the data\n",
    "grid_search_lr.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and the corresponding accuracy score\n",
    "best_params_lr = grid_search_lr.best_params_\n",
    "best_score_lr = grid_search_lr.best_score_\n",
    "\n",
    "# Testing GridSearch Model with Test Data\n",
    "accuracy_score_grid_search_lr = accuracy_score(y_test, grid_search_lr.predict(X_test))\n",
    "\n",
    "print('Best Parameters for Logistic Regression:', best_params_lr)\n",
    "print('Best Accuracy Score for Logistic Regression:', best_score_lr)\n",
    "\n",
    "print('GridSearch Logistic Regression with Test Data', accuracy_score_grid_search_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b07d57-523e-4fff-82e0-ae5bf749154b",
   "metadata": {},
   "source": [
    "### Doing GridSearch on LinearDiscriminantAnalysis, another best Model with Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c64fefb4-d1d0-4e13-8e71-b6c24912e597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "Best Parameters for Linear Discriminant Analysis: {'n_components': None, 'solver': 'svd', 'tol': 0.0001}\n",
      "Best Accuracy Score for Linear Discriminant Analysis: 0.64607106817647\n",
      "GridSearch LDA with Test Data 0.6317991631799164\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for LDA\n",
    "param_grid_lda = {\n",
    "    'solver': ['svd', 'lsqr', 'eigen'],\n",
    "    'n_components': [None, 1],\n",
    "    'tol': [1e-4, 1e-3, 1e-2],\n",
    "}\n",
    "\n",
    "# Create the LDA model\n",
    "lda_model = LinearDiscriminantAnalysis()\n",
    "\n",
    "# Create GridSearchCV object for LDA\n",
    "grid_search_lda = GridSearchCV(estimator=lda_model, param_grid=param_grid_lda, scoring='accuracy', cv=5, n_jobs=-1, verbose=100)\n",
    "\n",
    "# Fit the LDA model to the data\n",
    "grid_search_lda.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and the corresponding accuracy score\n",
    "best_params_lda = grid_search_lda.best_params_\n",
    "best_score_lda = grid_search_lda.best_score_\n",
    "\n",
    "# Testing GridSearch Model with Test Data\n",
    "accuracy_score_grid_search_lda = accuracy_score(y_test, grid_search_lda.predict(X_test))\n",
    "\n",
    "print('Best Parameters for Linear Discriminant Analysis:', best_params_lda)\n",
    "print('Best Accuracy Score for Linear Discriminant Analysis:', best_score_lda)\n",
    "\n",
    "print('GridSearch LDA with Test Data', accuracy_score_grid_search_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb4d9c9-2ca3-4eea-80bd-ff63e5ab448e",
   "metadata": {},
   "source": [
    "### Doing GridSearch on KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "191c6370-fbc9-43e6-b5cc-994faf710371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "Best Parameters for KNeighborsClassifier: {'algorithm': 'auto', 'n_neighbors': 9, 'p': 2, 'weights': 'uniform'}\n",
      "Best Accuracy Score for KNeighborsClassifier: 0.5906425704413076\n",
      "GridSearch KNeighborsClassifier with Test Data 0.5891974134651959\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for KNeighborsClassifier\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'p': [1, 2]\n",
    "}\n",
    "\n",
    "# Create the KNeighborsClassifier model\n",
    "knn_model = KNeighborsClassifier()\n",
    "\n",
    "# Create GridSearchCV object for KNeighborsClassifier\n",
    "grid_search_knn = GridSearchCV(estimator=knn_model, param_grid=param_grid_knn, scoring='accuracy', cv=5, n_jobs=-1, verbose=100)\n",
    "\n",
    "# Fit the KNeighborsClassifier model to the data\n",
    "grid_search_knn.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and the corresponding accuracy score\n",
    "best_params_knn = grid_search_knn.best_params_\n",
    "best_score_knn = grid_search_knn.best_score_\n",
    "\n",
    "# Testing GridSearch Model with Test Data\n",
    "accuracy_score_grid_search_knn = accuracy_score(y_test, grid_search_knn.predict(X_test))\n",
    "\n",
    "print('Best Parameters for KNeighborsClassifier:', best_params_knn)\n",
    "print('Best Accuracy Score for KNeighborsClassifier:', best_score_knn)\n",
    "\n",
    "print('GridSearch KNeighborsClassifier with Test Data', accuracy_score_grid_search_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e152e1da-cbe4-40f4-be19-f0028ffd52d1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Doing GridSearch on RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8af355bf-2e4f-41cd-b1ef-55f3f82451d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Best Parameters for RandomForestClassifier: {'max_depth': 11, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 6, 'n_estimators': 65}\n",
      "Best Accuracy Score for RandomForestClassifier: 0.6463973324505318\n",
      "GridSearch RandomForestClassifier with Test Data 0.6321795359452264\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for RandomForestClassifier\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [65, 70, 75],  # Number of trees in the forest\n",
    "    'max_features': ['sqrt'],  # Number of features to consider at each split\n",
    "    'max_depth': [9, 10, 11],  # Maximum depth of the trees\n",
    "    'min_samples_split': [5, 6, 7],  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 3]  # Minimum number of samples required to be at a leaf node\n",
    "}\n",
    "\n",
    "\n",
    "# Create the RandomForestClassifier model\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# Create GridSearchCV object for RandomForestClassifier\n",
    "grid_search_rf = GridSearchCV(estimator=rf_model, param_grid=param_grid_rf, scoring='accuracy', cv=5, n_jobs=-1, verbose=100)\n",
    "\n",
    "# Fit the RandomForestClassifier model to the data\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and the corresponding accuracy score\n",
    "best_params_rf = grid_search_rf.best_params_\n",
    "best_score_rf = grid_search_rf.best_score_\n",
    "\n",
    "# Testing GridSearch Model with Test Data\n",
    "accuracy_score_grid_search_rf = accuracy_score(y_test, grid_search_rf.predict(X_test))\n",
    "\n",
    "print('Best Parameters for RandomForestClassifier:', best_params_rf)\n",
    "print('Best Accuracy Score for RandomForestClassifier:', best_score_rf)\n",
    "\n",
    "print('GridSearch RandomForestClassifier with Test Data', accuracy_score_grid_search_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6475c5-1422-4af5-903a-c189bd0fd387",
   "metadata": {},
   "source": [
    "### Doing GridSearch on AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05b939b6-e0c1-4afa-99db-e28916a13fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "Best Parameters for AdaBoostClassifier: {'algorithm': 'SAMME', 'learning_rate': 0.01, 'n_estimators': 50}\n",
      "Best Accuracy Score for AdaBoostClassifier: 0.64607106817647\n",
      "GridSearch AdaBoostClassifier with Test Data 0.6317991631799164\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for AdaBoostClassifier\n",
    "param_grid_ada = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'learning_rate': [0.01, 0.1, 1.0],\n",
    "    'algorithm': ['SAMME', 'SAMME.R']\n",
    "}\n",
    "\n",
    "# Create the AdaBoostClassifier model\n",
    "ada_model = AdaBoostClassifier()\n",
    "\n",
    "# Create GridSearchCV object for AdaBoostClassifier\n",
    "grid_search_ada = GridSearchCV(estimator=ada_model, param_grid=param_grid_ada, scoring='accuracy', cv=5, n_jobs=-1, verbose=100)\n",
    "\n",
    "# Fit the AdaBoostClassifier model to the data\n",
    "grid_search_ada.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and the corresponding accuracy score\n",
    "best_params_ada = grid_search_ada.best_params_\n",
    "best_score_ada = grid_search_ada.best_score_\n",
    "\n",
    "# Testing GridSearch Model with Test Data\n",
    "accuracy_score_grid_search_ada = accuracy_score(y_test, grid_search_ada.predict(X_test))\n",
    "\n",
    "print('Best Parameters for AdaBoostClassifier:', best_params_ada)\n",
    "print('Best Accuracy Score for AdaBoostClassifier:', best_score_ada)\n",
    "\n",
    "print('GridSearch AdaBoostClassifier with Test Data', accuracy_score_grid_search_ada)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fde271-befe-47e8-85eb-3d4e7bea71fb",
   "metadata": {},
   "source": [
    "### Doing GridSearch on GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25af9354-bac5-4a5b-b11a-06455172c22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n",
      "Best Parameters for GradientBoostingClassifier: {'learning_rate': 0.01, 'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Best Accuracy Score for GradientBoostingClassifier: 0.64607106817647\n",
      "GridSearch GradientBoostingClassifier with Test Data 0.6317991631799164\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for GradientBoostingClassifier\n",
    "param_grid_gb = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Create the GradientBoostingClassifier model\n",
    "gb_model = GradientBoostingClassifier()\n",
    "\n",
    "# Create GridSearchCV object for GradientBoostingClassifier\n",
    "grid_search_gb = GridSearchCV(estimator=gb_model, param_grid=param_grid_gb, scoring='accuracy', cv=5, n_jobs=-1, verbose=100)\n",
    "\n",
    "# Fit the GradientBoostingClassifier model to the data\n",
    "grid_search_gb.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and the corresponding accuracy score\n",
    "best_params_gb = grid_search_gb.best_params_\n",
    "best_score_gb = grid_search_gb.best_score_\n",
    "\n",
    "# Testing GridSearch Model with Test Data\n",
    "accuracy_score_grid_search_gb = accuracy_score(y_test, grid_search_gb.predict(X_test))\n",
    "\n",
    "print('Best Parameters for GradientBoostingClassifier:', best_params_gb)\n",
    "print('Best Accuracy Score for GradientBoostingClassifier:', best_score_gb)\n",
    "\n",
    "print('GridSearch GradientBoostingClassifier with Test Data', accuracy_score_grid_search_gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c17d871-abbf-4365-9222-69542debfa77",
   "metadata": {},
   "source": [
    "## Saving the Best Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78d6316f-be45-4b8b-a542-71618abcb841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/model_rf.pk1']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(grid_search_rf, \"models/model_rf.pk1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
